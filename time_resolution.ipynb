{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Resolution Scan Analysis\n",
    "\n",
    "This notebook use the template created with [template_scan_analysis.ipynb](template_scan_analysis.ipynb). follow initial instructions there and run the notebook till the end.\n",
    "\n",
    "Let us quickly check if the file is really here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls pulse_template.npz\n",
    "!ls /mnt/baobab/sst1m/raw/2018/05/25/SST1M_01/SST1M_01_20180525_*.fits.fz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the needed libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "from digicampipe.io.event_stream import calibration_event_stream\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm #  progress bar\n",
    "from ctapipe.instrument import CameraGeometry\n",
    "from ctapipe.visualization import CameraDisplay\n",
    "from astropy import units as u\n",
    "from scipy.stats.distributions import chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the pulse template data and compute the boolean 2D array which indicates which indexes from the template to match camera data for all possibles offset between 0 an 4 ns (1 line per offset, 1 column per sample).\n",
    "We plot the pulse for the different offsets.\n",
    "\n",
    "As large offsets would cut the template pulse, we pad the template with 0 so it does not happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_sample = 50\n",
    "max_shift = 4 \n",
    "template_pulse = np.load('pulse_template.npz')\n",
    "x = template_pulse['x']\n",
    "delta_x = x[1] - x[0]\n",
    "y = template_pulse['y']\n",
    "dy = template_pulse['dy']\n",
    "print('loaded', template_pulse.keys(), 'from pulse template.')\n",
    "print('template with', len(x), 'points from t={:.4f} ns'.format(x[0]),\n",
    "      'to t={:.4f} ns'.format(x[-1]), 'delta x={:.4f} ns'.format(delta_x))\n",
    "oversampling = int(np.round(4 / delta_x)) #  samples in data are separated by 4ns\n",
    "n_offset = int(max_shift * oversampling)\n",
    "offsets = np.arange(n_offset) * delta_x\n",
    "print('template was oversampled ', oversampling, 'times compared to data.')\n",
    "y_max_idx = np.argmax(y)\n",
    "y_max = y[y_max_idx]\n",
    "\n",
    "\"\"\"\n",
    "rising_part = np.logical_and(y > 0.1 * y_max, y < 0.9 * y_max)\n",
    "rising_part = np.logical_and(rising_part, np.arange(len(x)) < y_max_idx)\n",
    "plt.figure()\n",
    "plt.errorbar(x[rising_part], y[rising_part], dy[rising_part], 0, '.', ms=0, color='b')\n",
    "plt.errorbar(x[~rising_part], y[~rising_part], dy[~rising_part], 0, '.', ms=0, color='r')\n",
    "plt.xlim(np.min(x[rising_part])-1, np.max(x[rising_part])+1)\n",
    "x=x[rising_part]\n",
    "y=y[rising_part]\n",
    "dy=dy[rising_part]\n",
    "\"\"\"\n",
    "\n",
    "plt.figure()\n",
    "for idx in range(n_offset):\n",
    "    offsets_idx = np.arange(idx, len(y), oversampling)\n",
    "    plt.plot(y[offsets_idx], '-')\n",
    "    plt.xlabel('sample')\n",
    "    plt.ylabel('normalized amplitude')\n",
    "    plt.title('samples for ' + str(n_offset) + ' offsets ({:.1f} ns)'.format(n_offset * delta_x))\n",
    "\n",
    "plt.figure()\n",
    "x_padded = np.hstack([np.zeros(max_shift*oversampling), x])\n",
    "y_padded = np.hstack([np.zeros(max_shift*oversampling), y])\n",
    "dy_padded = np.hstack([np.ones(max_shift*oversampling)*np.inf, dy])\n",
    "for idx in range(n_offset):\n",
    "    offsets_idx = np.arange(idx, len(y_padded), oversampling)\n",
    "    plt.plot(y_padded[offsets_idx], '-')\n",
    "    plt.xlabel('sample')\n",
    "    plt.ylabel('normalized amplitude')\n",
    "    plt.title('samples for ' + str(n_offset) + ' offsets ({:.1f} ns)'.format(n_offset * delta_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete old pre-analysed data. To be used if one changes parameters in the next cell and want to have new $\\chi^2$ computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_files = sorted(glob('/home/yves/ctasoft/digicampipe/data/SST1M_01_20180525_*_chi2.npz'))\n",
    "#output_files = sorted(glob('/mnt/baobab/sst1m/raw/2018/05/25/SST1M_01/SST1M_01_20180525_*_chi2.npz'))\n",
    "for output_file in output_files:\n",
    "    os.remove(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the raw camera files.\n",
    "For each event we normalize the pulse and roughly align it with the template.\n",
    "\n",
    "We then compute the $\\chi^2$ between the measured pulse and the template pulse. We average over all events and store an individual $\\chi^2$ value for each AC LEDs'DAC level, each time offset and each pixel.\n",
    "\n",
    "We store also the mean and the standart deviaton of the integrated pulse over all events for each LED level and each pixel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AC_levels = np.array([305])\n",
    "#AC_levels = np.array([100, 150, 200, 260, 305, 410, 510, 610, 650, 700, 745])\n",
    "AC_levels = np.arange(0, 750, 5)\n",
    "n_level = len(AC_levels)\n",
    "#input_files = ['/home/yves/ctasoft/digicampipe/data/SST1M_01_20180525_066.fits.fz']\n",
    "#input_files = sorted(glob('/home/yves/ctasoft/digicampipe/data/SST1M_01_20180525_*.fits.fz'))\n",
    "input_files = sorted(glob('/mnt/baobab/sst1m/raw/2018/05/25/SST1M_01/SST1M_01_20180525_*.fits.fz'))\n",
    "print(len(input_files), 'files for', n_level, 'AC levels')\n",
    "assert len(input_files) == n_level, \"ERROR: the number of AC LED levels and the number of files do not match.\"\n",
    "\n",
    "n_pixel = 1296\n",
    "electronic_noise = 1.1 * np.ones(n_pixel) # electronic noise in LSB\n",
    "zero_pe_integral = 10\n",
    "gain_integral = 22\n",
    "chi_squared = np.zeros([n_pixel, n_offset])\n",
    "pe = np.zeros([n_pixel])\n",
    "d_pe = np.zeros([n_pixel])\n",
    "for level_idx, level in enumerate(AC_levels):\n",
    "    archive_name = input_files[level_idx].replace('.fits.fz', '_chi2.npz').replace(\n",
    "        '/mnt/baobab/sst1m/raw/2018/05/25/SST1M_01/', '/home/yves/ctasoft/digicampipe/data/'\n",
    "    )\n",
    "    if os.path.isfile(archive_name):\n",
    "        print(input_files[level_idx], 'already_analysed, skiping it.')\n",
    "        continue\n",
    "    print('analyzing file', input_files[level_idx], 'for level', level, 'LSB')\n",
    "    events = calibration_event_stream([input_files[level_idx]])# , max_events=100)\n",
    "    n_events = np.zeros([n_pixel, n_offset], dtype=np.int)\n",
    "    integral_events = []\n",
    "    for e in events:\n",
    "        adcs = e.data.adc_samples[:, 10:30] - e.data.digicam_baseline[:, None]\n",
    "        integrals = adcs.sum(axis=1)\n",
    "        integral_events.append(integrals)\n",
    "        for idx in range(n_offset):\n",
    "            offsets_idx = np.arange(idx, len(y_padded), oversampling)\n",
    "            template_integral = np.sum(y_padded[offsets_idx])\n",
    "            adc_integral = np.sum(adcs[:, :len(offsets_idx)], axis=1, keepdims=True)\n",
    "            null_charge = (adc_integral <= 0).flatten()\n",
    "            adc_integral = adc_integral[~null_charge]\n",
    "            non_null_noise = electronic_noise[~null_charge]      \n",
    "            template = y_padded[None, offsets_idx] / template_integral * adc_integral\n",
    "            template_error = dy_padded[None, offsets_idx] / template_integral * adc_integral\n",
    "            n_sample_fitted = np.sum(~np.isinf(dy_padded[offsets_idx]))\n",
    "            squared_template_error = template_error**2 + non_null_noise[:, None]**2\n",
    "            squared_diff_data_template = (adcs[~null_charge, :len(offsets_idx)] - template)**2\n",
    "            chi_squared_pixels = np.sum(squared_diff_data_template/squared_template_error, axis=-1)\n",
    "            chi_squared[~null_charge, idx] += chi_squared_pixels / n_sample_fitted\n",
    "            n_events[:, idx] += ~null_charge\n",
    "            assert np.any(np.isnan(squared_template_error)) == False\n",
    "            assert np.any(np.isnan(squared_diff_data_template)) == False\n",
    "            assert np.all(squared_template_error > 0)\n",
    "    chi_squared[n_events>0] /= n_events[n_events>0]\n",
    "    chi_squared[n_events==0] = np.nan\n",
    "    integral_events = np.array(integral_events)\n",
    "    pe = (np.mean(integral_events, axis=0) - zero_pe_integral) / gain_integral\n",
    "    d_pe = (np.std(integral_events, axis=0) - zero_pe_integral) / gain_integral\n",
    "    np.savez(archive_name, \n",
    "             #integral_events=integral_events, \n",
    "             pe=pe, \n",
    "             d_pe=d_pe, \n",
    "             chi_squared=chi_squared,\n",
    "             AC_level=level,\n",
    "             input_file=input_files[level_idx],\n",
    "             electronic_noise=electronic_noise)\n",
    "print('done')\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the measured charge fluctuations function of the measured charge. The charge is calculated for each pixel and each light level from the integral pulse divided by the gain.\n",
    "We see the fluctuation is proportional to $\\sqrt{p.e.}$ as expected from a Poissonian process until ~700 p.e.\n",
    "\n",
    "We also plot for each pixel the relation between the LEDs AC level and the measured charge. The limit before saturation (700 p.e.) is shown in red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_files = sorted(glob('/home/yves/ctasoft/digicampipe/data/SST1M_01_20180525_*_chi2.npz'))\n",
    "#output_files = sorted(glob('/mnt/baobab/sst1m/raw/2018/05/25/SST1M_01/SST1M_01_20180525_*_chi2.npz'))\n",
    "n_pixel = 1296\n",
    "n_level = len(output_files)\n",
    "AC_levels = np.zeros(n_level)\n",
    "all_integral_events = []\n",
    "chi_squared = np.zeros([n_level, n_pixel, n_offset])\n",
    "pe = np.zeros([n_level, n_pixel])\n",
    "d_pe = np.zeros([n_level, n_pixel])\n",
    "electronic_noise = np.zeros([n_level, n_pixel])\n",
    "for i, output_file in enumerate(output_files):\n",
    "    data = np.load(output_file)\n",
    "    #integral_events = data['integral_events'].copy()\n",
    "    pe[i, :] = data['pe'].copy()\n",
    "    d_pe[i, :] = data['d_pe'].copy()\n",
    "    chi_squared[i, :, :] = data['chi_squared'].copy()\n",
    "    AC_levels[i] = data['AC_level'].copy()\n",
    "    electronic_noise[i, :] = data['electronic_noise'].copy()\n",
    "del data\n",
    "print(len(output_files), 'result files loaded.')\n",
    "#print(chi_squared[1, 16, :])\n",
    "\"\"\"\n",
    "events_pe = (all_integral_events - zero_pe_integral) / gain_integral\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(events_pe.flatten(), np.arange(-10.5/22, 10, 1/22))\n",
    "plt.xlabel('charge [p.e.]')\n",
    "plt.ylabel('counts')\n",
    "plt.yscale('log', nonposy='clip')\n",
    "\"\"\"\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "#plt.plot(pe.flatten(), d_pe.flatten() ,'+', label='measured')\n",
    "plt.scatter(pe.flatten(), d_pe.flatten(), 1, np.log10(np.nanmin(chi_squared, axis=2)).flatten(), label='measured')\n",
    "plt.plot(np.logspace(-1, 3, 100), np.sqrt(np.logspace(-1, 3, 100)), 'k--', label='$\\sqrt{p.e.}$')\n",
    "plt.plot([700, 700], [0, np.max(d_pe)], 'r--')\n",
    "plt.title('mean charge function of charge variation for all pixels and all levels')\n",
    "plt.xlabel('mean charge measured [p.e.]')\n",
    "plt.ylabel('std charge measured [p.e.]')\n",
    "plt.xscale('log', nonposx='clip')\n",
    "plt.yscale('log', nonposy='clip')\n",
    "cbar = plt.colorbar()\n",
    "#plt.clim(-1, 2)\n",
    "cbar.set_label('$\\log_{10}(\\chi^2) for best offset$')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(AC_levels, pe, lw=1)\n",
    "plt.plot([AC_levels[0], AC_levels[-1]], [700, 700], 'r--')\n",
    "plt.title('charge measured function of DAC level of the LEDs for each pixel')\n",
    "plt.xlabel('DAC level of AC LEDs')\n",
    "plt.ylabel('charge measured [p.e.]')\n",
    "#plt.xlim(0, 400)\n",
    "plt.ylim(0, 50)\n",
    "\n",
    "DAC_offset = np.zeros(n_pixel)\n",
    "for pix in range(n_pixel):\n",
    "    levels_ok = pe[:, pix] < 50\n",
    "    poly = np.polyfit(AC_levels[levels_ok], pe[levels_ok, pix], 4)\n",
    "    poly_shifted = poly.copy()\n",
    "    poly_shifted[-1] -= 10\n",
    "    DAC_offset[pix] = np.real(np.roots(poly_shifted)[0])\n",
    "\n",
    "DAC_offset_ok = np.logical_and(DAC_offset>100, DAC_offset<700)\n",
    "DAC_offset_ref = np.min(DAC_offset[DAC_offset_ok])\n",
    "print('DAC_offset_ref:', DAC_offset_ref)\n",
    "DAC_offset -= DAC_offset_ref\n",
    "DAC_offset[~DAC_offset_ok] = 0\n",
    "print(DAC_offset.astype(int).tolist())\n",
    "\n",
    "geom = CameraGeometry.from_name(\"DigiCam\")\n",
    "geom.rotate(90 * u.deg)\n",
    "plt.figure(figsize=(10, 8))\n",
    "disp = CameraDisplay(geom)\n",
    "disp.image = DAC_offset\n",
    "disp.highlight_pixels(~DAC_offset_ok, color='red', linewidth=3)\n",
    "#disp.set_limits_minmax(0, 700)\n",
    "disp.add_colorbar()\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we would like the uncertaincy for each pixel function of the charge, we will now fit the offset for all LEDs's AC levels.\n",
    "Then we plot an histogram of the residuals of the parabola fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_squared_max = 100\n",
    "points_rel = np.arange(-15, 16, 1)\n",
    "\n",
    "n_point_fit = len(points_rel)\n",
    "polys = np.ones([3, n_level, n_pixel]) * np.nan\n",
    "residuals = np.ones([n_level, n_pixel]) * np.nan\n",
    "index_offset_rel = np.ones([n_level, n_pixel]) * np.nan\n",
    "plt.figure(figsize=(12, 6))\n",
    "for level_idx in range(n_level):\n",
    "    bad_pixels = np.any(np.isnan(chi_squared[level_idx, :, :]), axis=-1)\n",
    "    saturated_pixels = pe[level_idx, :] > 800\n",
    "    dark_pixels = pe[level_idx, :] < 0.5\n",
    "    pixels_ok_bool = np.logical_and(~bad_pixels, ~saturated_pixels)\n",
    "    pixels_ok_bool = np.logical_and(pixels_ok_bool, ~dark_pixels)\n",
    "    #pixels_ok_bool = np.logical_and(pixels_ok_bool, ~problematic_pixels)\n",
    "    pixels_ok = np.arange(n_pixel)[pixels_ok_bool]\n",
    "    # print('level', AC_levels[level_idx], ':', len(pixels_ok), '/', n_pixel, 'fits are ok')\n",
    "    chi_squared_level = chi_squared[level_idx, pixels_ok, :]\n",
    "    index_best_offsets = np.nanargmin(chi_squared_level, axis=-1)\n",
    "    index_best_offsets[index_best_offsets < -np.min(points_rel)] = -np.min(points_rel)\n",
    "    index_best_offsets[index_best_offsets >= n_offset - np.max(points_rel)] =  n_offset - np.max(points_rel) -1\n",
    "    fit_points_bool = np.zeros([len(pixels_ok), n_offset], dtype=bool)\n",
    "    for k in points_rel:\n",
    "        fit_points_bool = np.logical_or(fit_points_bool, np.eye(n_offset,k=k)[index_best_offsets])\n",
    "    # we fit parabolas\n",
    "    chi_squared_fit = chi_squared_level[fit_points_bool].reshape(len(pixels_ok), n_point_fit)\n",
    "    if chi_squared_fit.shape[0] == 0:\n",
    "        print(\"no good pixel found for level\", AC_levels[level_idx])\n",
    "        continue\n",
    "    polys_level, residuals_level, _, _, _ = np.polyfit(points_rel*delta_x, chi_squared_fit.transpose(), 2, full=True)\n",
    "    polys[:, level_idx, pixels_ok] = polys_level\n",
    "    residuals[level_idx, pixels_ok] = residuals_level\n",
    "    index_offset_rel[level_idx, pixels_ok] = index_best_offsets\n",
    "    #plot the fitted parabollas\n",
    "    #plt.plot(points_rel*delta_x, chi_squared_fit.transpose(), '-', lw=1)\n",
    "    #plt.xlabel('offset [ns]')\n",
    "    #plt.ylabel('$\\chi^2 /(N-1)$')\n",
    "    #plt.ylim([0, chi_squared_max])\n",
    "polys = polys.reshape(3, -1)\n",
    "offset_fit_rel = np.ones([n_level* n_pixel]) * np.nan\n",
    "offset_fit_rel = (-0.5 * polys[1, :] / polys[0, :])\n",
    "offset_fit = offset_fit_rel.reshape(n_level, n_pixel) + index_offset_rel * delta_x\n",
    "d_offset_fit = np.ones([n_level* n_pixel]) * np.nan\n",
    "d_offset_fit = (np.sqrt(1./polys[0, :]))\n",
    "d_offset_fit = d_offset_fit.reshape(n_level, n_pixel)\n",
    "chi_squared_fit_min = polys[2, :].copy()\n",
    "residuals = residuals.reshape(-1)\n",
    "\n",
    "\"\"\"\n",
    "# we plot the residuals\n",
    "plt.figure(figsize=(12, 6))\n",
    "h, xh, _ = plt.hist(residuals[~np.isnan(residuals)], np.logspace(-1, 3, 200))\n",
    "plt.xlabel('residuals')\n",
    "plt.ylabel('counts')\n",
    "plt.xscale('log', nonposx='clip')\n",
    "plt.yscale('log', nonposy='clip')\n",
    "\"\"\"\n",
    "fit_ok = ~np.isnan(residuals)\n",
    "# residuals function of min chi2\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "axes = fig.subplots(2, sharex=True)\n",
    "h0=axes[0].scatter(pe.flatten()[fit_ok], offset_fit.flatten()[fit_ok], 1 ,d_offset_fit.flatten()[fit_ok])#, vmin=7, vmax=12)\n",
    "cbar0 = plt.colorbar(h0, ax=axes[0])\n",
    "cbar0.set_label('offset uncertaincy [ns]')\n",
    "axes[0].set_xscale('log', nonposx='clip')\n",
    "axes[0].set_xlabel('charge [p.e.]')\n",
    "axes[0].set_ylabel('fitted offset [ns]')\n",
    "axes[0].set_title('fitted offset function of charge for all pixels and light levels')\n",
    "#axes[0].set_ylim([7, 15])\n",
    "h1 = axes[1].scatter(pe.flatten()[fit_ok], offset_fit.flatten()[fit_ok], 1, chi_squared_fit_min.flatten()[fit_ok], vmin=0, vmax=10)\n",
    "cbar1 = plt.colorbar(h1, ax=axes[1])\n",
    "cbar1.set_label('$\\chi^2_{min}$')\n",
    "axes[1].set_xscale('log', nonposx='clip')\n",
    "axes[1].set_xlabel('charge [p.e.]')\n",
    "axes[1].set_ylabel('fitted offset [ns]')\n",
    "axes[1].set_title('fitted offset function of charge for all pixels and light levels')\n",
    "#axes[1].set_ylim([7, 15])\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the offset and the uncertaincy as previously but for all light levels giving a reasonable fit.\n",
    "Some aditional attention must be taken as we are fitting on less than optimal data.\n",
    "\n",
    "There are for each pixel ~3 functional fits, and they are consistent with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We discard the fits where the residuals are too large.\n",
    "fit_ok = chi_squared_fit_min < 10\n",
    "fit_ok = np.logical_and(fit_ok, chi_squared_fit_min > .1)\n",
    "fit_ok = np.logical_and(fit_ok, chi_squared_fit_min < 10)\n",
    "fit_ok = np.logical_and(fit_ok, offset_fit.flatten() > 7)\n",
    "fit_ok = np.logical_and(fit_ok, offset_fit.flatten() < 12)\n",
    "print(np.sum(fit_ok), '/', len(fit_ok.flatten()), 'fits succeded')\n",
    "delta_chi_square = np.polyval(polys, offset_fit_rel - d_offset_fit.flatten()) - chi_squared_fit_min\n",
    "\n",
    "# Now we check the hypothesis made to calculate the uncertaincy still holds. When too much off, we discard the fit.\n",
    "fit_ok = np.logical_and(fit_ok, delta_chi_square > 0.8)\n",
    "offset_fit_rel[~fit_ok] = np.nan\n",
    "offset_fit.flatten()[~fit_ok] = np.nan\n",
    "d_offset_fit.flatten()[~fit_ok] = np.nan\n",
    "chi_squared_fit_min[~fit_ok] = np.nan\n",
    "print(np.sum(fit_ok), '/', len(fit_ok), 'fits succeded after further checks')\n",
    "std_offset_fitted = np.nanstd(offset_fit, axis=0)\n",
    "std_offset_fitted_mean = np.nanmean(std_offset_fitted[std_offset_fitted>0])\n",
    "std_offset_fitted_min = np.nanmin(std_offset_fitted[std_offset_fitted>0])\n",
    "print('the average over all pixels of the deviation of the fitted offset over the AC levels is:', std_offset_fitted)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(np.arange(len(fit_ok))[fit_ok], delta_chi_square[fit_ok], '+')\n",
    "plt.plot(np.arange(len(fit_ok))[~fit_ok], delta_chi_square[~fit_ok], '+')\n",
    "plt.plot([0, len(fit_ok)], [1, 1], 'k--')\n",
    "plt.title('$\\Delta \\chi^2$ at $1 \\sigma$ (should be ~1)')\n",
    "plt.xlabel('fit #')\n",
    "plt.ylabel('$\\Delta \\chi^2$')\n",
    "plt.ylim(0, 1.1)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(offset_fit.transpose(), '+')\n",
    "plt.xlabel('pixel #')\n",
    "plt.ylabel('offset [ns]')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(d_offset_fit.transpose(), '+')\n",
    "plt.plot([0, d_offset_fit.shape[1]], std_offset_fitted_mean * np.ones(2), '--k')\n",
    "plt.plot([0, d_offset_fit.shape[1]], std_offset_fitted_min * np.ones(2), '--k')\n",
    "plt.xlabel('pixel #')\n",
    "plt.ylabel('error on offset [ns]')\n",
    "plt.yscale('log', nonposy='clip')\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we plot :\n",
    "- the uncertaincy function of the LEDs AC level\n",
    "- the uncertaincy function of the charge\n",
    "\n",
    "It is very uniform around 0.22 ns in the 20 - 700 p.e. range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "pixels_plot = (np.ones([len(AC_levels), 1]) * np.arange(n_pixel))\n",
    "levels_plot = (np.ones([n_pixel, 1]) * AC_levels).transpose()\n",
    "plt.scatter(pixels_plot.flatten(), levels_plot.flatten(), 5, np.log10(pe).flatten(), '+')\n",
    "plt.xlabel('pixel #')\n",
    "plt.ylabel('LED AC level')\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('$\\log_{10}$(charge [p.e.])')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(np.ones([n_pixel, 1]) * AC_levels, d_offset_fit, 5, np.log10(pe), '+')\n",
    "plt.xlabel('LED AC level')\n",
    "plt.ylabel('error on offset [ns]')\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('$\\log_{10}$(charge [p.e.])')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(pe.flatten()[fit_ok], d_offset_fit.flatten()[fit_ok],5, np.log10(chi_squared_fit_min[fit_ok]), '+')\n",
    "plt.xlim([1, 1000])\n",
    "plt.ylim([0.1, 10])\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('$\\log_{10}(\\chi^2)$')\n",
    "plt.xscale('log', nonposx='clip')\n",
    "plt.yscale('log', nonposy='clip')\n",
    "plt.xlabel('measured charge [p.e.]')\n",
    "plt.ylabel('error on offset [ns]')\n",
    "plt.title('timing resolution function of charge')\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try to understand the patern of the measured offset.\n",
    "\n",
    "No obvious correlation with sectors nor boards nor pixel index in boards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_offsets = np.nan*np.ones(n_pixel)\n",
    "best_d_offsets = np.nan*np.ones(n_pixel)\n",
    "bad_pixels = np.all(np.isnan(d_offset_fit), axis=0)\n",
    "best_levels = np.nanargmin(d_offset_fit[:, ~bad_pixels], axis=0)\n",
    "best_offsets[~bad_pixels]  = offset_fit[best_levels, ~bad_pixels]\n",
    "best_d_offsets[~bad_pixels] = d_offset_fit[best_levels, ~bad_pixels]\n",
    "geom = CameraGeometry.from_name(\"DigiCam\")\n",
    "geom.rotate(90 * u.deg)\n",
    "\n",
    "plt.scatter(np.arange(n_pixel), best_offsets, 5,  best_d_offsets)\n",
    "plt.figure(figsize=(10, 8))\n",
    "disp = CameraDisplay(geom)\n",
    "disp.image = best_offsets\n",
    "disp.highlight_pixels(bad_pixels, color='red', linewidth=3)\n",
    "#disp.set_limits_minmax(np.min(offset_fit), np.max(offset_fit))\n",
    "disp.set_limits_minmax(7, 12)\n",
    "disp.add_colorbar()\n",
    "plt.title('measured time offset [ns]')\n",
    "#disp.overlay_pixels_id()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "disp = CameraDisplay(geom)\n",
    "disp.image = best_d_offsets\n",
    "disp.set_limits_minmax(0, 0.3)\n",
    "disp.highlight_pixels(bad_pixels, color='red', linewidth=3)\n",
    "cbar = disp.add_colorbar()\n",
    "plt.title('uncertaincy on time offset [ns]')\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches_to_pixels[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels_to_patches[755]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
